The chapter opens with the following quote from Microsoft about Cortana,

“This new category of the personal digital assistant is a runtime, a new interface. It can take text input. It can take speech input. It knows you deeply. It knows your context, your family, your work. It knows the world. It is unbounded. In other words, it’s about you; it’s not about any one device. It goes wherever you go. It’s available on any phone—iOS, Android, Windows—doesn’t matter. It is available across all of the applications that you will use in your life.”

It is ironic that this quote is supposed to be used as a selling point for Cortana but out of anything this makes me want to avoid Cortana even more. Like why would Cortana need to know my personal life to be able to assist me with things on my computer/phone? Also, it sounds like Cortana is meant to be personalized which obviously means that they would need to collect data about you to use in personalizing which again is concerning. They seem to conveniently not mention needing to collect data for this.

Zuboff discusses how the new use for computer interactions is “Personalization and customization” which clearly implies a heavy reliance of data about the user. New digital assistants are a prime example of the new predictive product using the new approach of “Personalization and customization”.

This quote is from a Google executive and is interesting to say the least,

“One Google executive reasoned that Google already knows all of this about you, so it might as well turn it into a service that can provide the company with access to even more information…”

The executive is saying they already have so much data on you so why shouldn’t they just collect more so that they can better help you. The problem is Google is not devoting all this money to this with the goal of helping you, they are doing it because they are a business and see this as a point to make profit, as all businesses do. This could be as simple as using the assistant as a new means of suggesting products for the user to purchase similar to current ads or even using the assistant as a means to influence the user to do actions that Google wants them to do. One goal they have aimed at is casual conversation with the assistant which helps blur the line between it and us. The main goal of this is for us to become more trusting of the assistant, which in turn makes it easier to manipulate us.

The predictive nature of all this reminds me of psychohistory from Issac Asimov’s Foundation series.